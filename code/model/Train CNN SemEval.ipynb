{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow\n",
    "\n",
    "from cnn import CNN\n",
    "from reader import Reader\n",
    "from sklearn.metrics import classification_report, confusion_matrix \n",
    "import numpy as np\n",
    "from tensorflow.keras.utils import to_categorical\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "EPOCHS = 10\n",
    "BATCH_SIZE = 128\n",
    "NUM_CLASSES = 2\n",
    "LEARN_RATE = 0.01\n",
    "EMBED_SIZE = 50\n",
    "FILENAME = \"data/sem_eval_all.pkl\"\n",
    "OVERSAMPLING_RATE = 3\n",
    "VOCAB_LEN = 10000\n",
    "MAX_LEN = 100\n",
    "LOSS_TYPE = \"logits\"\n",
    "\n",
    "reader = Reader(filename=FILENAME, num_classes=NUM_CLASSES, vocab_len=VOCAB_LEN)\n",
    "X, y = reader.load()\n",
    "\n",
    "mapping = {'hate': 1,'none': 0}\n",
    "y = [mapping[b] for b in y]\n",
    "\n",
    "X_train, X_test, y_train, y_test = reader.split(X, y)\n",
    "\n",
    "# Oversampling after split\n",
    "hate = [i for i in range(len(y_train)) if y_train[i]==1]\n",
    "X_train = X_train + [X_train[x] for x in hate]*(OVERSAMPLING_RATE-1)\n",
    "y_train = y_train + [1 for i in range(len(hate))]*(OVERSAMPLING_RATE-1)\n",
    "\n",
    "X_train = np.asarray(X_train)\n",
    "X_test = np.asarray(X_test)\n",
    "y_train = to_categorical(y_train, num_classes=NUM_CLASSES)\n",
    "y_test = to_categorical(y_test, num_classes=NUM_CLASSES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = CNN(max_len=MAX_LEN,\n",
    "          num_classes=NUM_CLASSES, \n",
    "          batch_size=BATCH_SIZE, \n",
    "          epochs=EPOCHS, \n",
    "          embed_size=EMBED_SIZE, \n",
    "          vocab_len=VOCAB_LEN,\n",
    "          loss_type=LOSS_TYPE,\n",
    "          save_model=True,\n",
    "          save_path=\"results/cnn-10-epochs-sem-eval-logits\",\n",
    "          checkpoint_path=\"results/cnn-10-epochs-sem-eval-logits.ckpt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "156/156 [==============================] - ETA: 0s - loss: 1.0059 - accuracy: 0.6817\n",
      "Epoch 1: saving model to results\\cnn-10-epochs-sem-eval-logits.ckpt\n",
      "156/156 [==============================] - 73s 350ms/step - loss: 1.0059 - accuracy: 0.6817\n",
      "Epoch 2/10\n",
      "156/156 [==============================] - ETA: 0s - loss: 0.5595 - accuracy: 0.6912\n",
      "Epoch 2: saving model to results\\cnn-10-epochs-sem-eval-logits.ckpt\n",
      "156/156 [==============================] - 16s 101ms/step - loss: 0.5595 - accuracy: 0.6912\n",
      "Epoch 3/10\n",
      "156/156 [==============================] - ETA: 0s - loss: 0.4803 - accuracy: 0.8186\n",
      "Epoch 3: saving model to results\\cnn-10-epochs-sem-eval-logits.ckpt\n",
      "156/156 [==============================] - 14s 87ms/step - loss: 0.4803 - accuracy: 0.8186\n",
      "Epoch 4/10\n",
      "156/156 [==============================] - ETA: 0s - loss: 0.4029 - accuracy: 0.8785\n",
      "Epoch 4: saving model to results\\cnn-10-epochs-sem-eval-logits.ckpt\n",
      "156/156 [==============================] - 15s 98ms/step - loss: 0.4029 - accuracy: 0.8785\n",
      "Epoch 5/10\n",
      "156/156 [==============================] - ETA: 0s - loss: 0.3376 - accuracy: 0.9122\n",
      "Epoch 5: saving model to results\\cnn-10-epochs-sem-eval-logits.ckpt\n",
      "156/156 [==============================] - 14s 90ms/step - loss: 0.3376 - accuracy: 0.9122\n",
      "Epoch 6/10\n",
      "156/156 [==============================] - ETA: 0s - loss: 0.2882 - accuracy: 0.9278\n",
      "Epoch 6: saving model to results\\cnn-10-epochs-sem-eval-logits.ckpt\n",
      "156/156 [==============================] - 13s 85ms/step - loss: 0.2882 - accuracy: 0.9278\n",
      "Epoch 7/10\n",
      "156/156 [==============================] - ETA: 0s - loss: 0.2548 - accuracy: 0.9380\n",
      "Epoch 7: saving model to results\\cnn-10-epochs-sem-eval-logits.ckpt\n",
      "156/156 [==============================] - 13s 85ms/step - loss: 0.2548 - accuracy: 0.9380\n",
      "Epoch 8/10\n",
      "156/156 [==============================] - ETA: 0s - loss: 0.2287 - accuracy: 0.9459\n",
      "Epoch 8: saving model to results\\cnn-10-epochs-sem-eval-logits.ckpt\n",
      "156/156 [==============================] - 14s 89ms/step - loss: 0.2287 - accuracy: 0.9459\n",
      "Epoch 9/10\n",
      "156/156 [==============================] - ETA: 0s - loss: 0.2107 - accuracy: 0.9487\n",
      "Epoch 9: saving model to results\\cnn-10-epochs-sem-eval-logits.ckpt\n",
      "156/156 [==============================] - 13s 84ms/step - loss: 0.2107 - accuracy: 0.9487\n",
      "Epoch 10/10\n",
      "156/156 [==============================] - ETA: 0s - loss: 0.1939 - accuracy: 0.9546\n",
      "Epoch 10: saving model to results\\cnn-10-epochs-sem-eval-logits.ckpt\n",
      "156/156 [==============================] - 13s 80ms/step - loss: 0.1939 - accuracy: 0.9546\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 3 of 3). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: results/cnn-10-epochs-sem-eval-logits\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: results/cnn-10-epochs-sem-eval-logits\\assets\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.engine.functional.Functional at 0x1d3551b32e0>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "38/38 [==============================] - 7s 170ms/step\n",
      "[[486 210]\n",
      " [168 336]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.74      0.70      0.72       696\n",
      "           1       0.62      0.67      0.64       504\n",
      "\n",
      "    accuracy                           0.69      1200\n",
      "   macro avg       0.68      0.68      0.68      1200\n",
      "weighted avg       0.69      0.69      0.69      1200\n",
      "\n"
     ]
    }
   ],
   "source": [
    "predictions = model.predict(X_test)\n",
    "classes = np.argmax(y_test, axis=1)\n",
    "\n",
    "predictions = list(map(lambda x: int(x), predictions))\n",
    "print(confusion_matrix(classes, predictions))\n",
    "print(classification_report(classes, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "38/38 [==============================] - 1s 16ms/step\n",
      "[[486 210]\n",
      " [168 336]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.74      0.70      0.72       696\n",
      "           1       0.62      0.67      0.64       504\n",
      "\n",
      "    accuracy                           0.69      1200\n",
      "   macro avg       0.68      0.68      0.68      1200\n",
      "weighted avg       0.69      0.69      0.69      1200\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model = CNN.load(\"results/cnn-10-epochs-sem-eval-logits\")\n",
    "predictions = model.predict(X_test)\n",
    "predictions = np.argmax(predictions, axis=1)\n",
    "classes = np.argmax(y_test, axis=1)\n",
    "\n",
    "predictions = list(map(lambda x: int(x), predictions))\n",
    "print(confusion_matrix(classes, predictions))\n",
    "print(classification_report(classes, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:tensorflow]",
   "language": "python",
   "name": "conda-env-tensorflow-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
