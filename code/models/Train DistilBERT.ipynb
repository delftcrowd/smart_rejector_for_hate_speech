{"cells":[{"cell_type":"markdown","metadata":{"id":"YFb53nvAS2Ng"},"source":["# DistilBERT model\n","This notebook trains the DistilBERT model and exports a set of predictions for a test dataset.\n","\n","**Trains on:** Waseem and Hovy (2016)"]},{"cell_type":"markdown","metadata":{"id":"1HD7NZIFUTAT"},"source":["First we need to install the required packages."]},{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":4110,"status":"ok","timestamp":1661779927150,"user":{"displayName":"Philippe Lammerts","userId":"17702421406505717674"},"user_tz":-120},"id":"wgEVB_DHBRjN","outputId":"6cd61291-16f4-4b8e-a0a5-e8490b104020"},"outputs":[{"name":"stdout","output_type":"stream","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Requirement already satisfied: transformers in /usr/local/lib/python3.7/dist-packages (4.21.2)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.21.6)\n","Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (21.3)\n","Requirement already satisfied: tokenizers!=0.11.3,<0.13,>=0.11.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.12.1)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (6.0)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2022.6.2)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.8.0)\n","Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers) (4.12.0)\n","Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.64.0)\n","Requirement already satisfied: huggingface-hub<1.0,>=0.1.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.9.1)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0,>=0.1.0->transformers) (4.1.1)\n","Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->transformers) (3.0.9)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers) (3.8.1)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2022.6.15)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.25.11)\n"]}],"source":["!pip install transformers"]},{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":3458,"status":"ok","timestamp":1661779930599,"user":{"displayName":"Philippe Lammerts","userId":"17702421406505717674"},"user_tz":-120},"id":"sD4XH6n5CWYf","outputId":"a26d9755-2b3e-49f3-9ac1-b3cf5eea11c5"},"outputs":[{"name":"stdout","output_type":"stream","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Requirement already satisfied: torch in /usr/local/lib/python3.7/dist-packages (1.12.1+cu113)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch) (4.1.1)\n"]}],"source":["!pip install torch"]},{"cell_type":"code","execution_count":3,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":3045,"status":"ok","timestamp":1661779933637,"user":{"displayName":"Philippe Lammerts","userId":"17702421406505717674"},"user_tz":-120},"id":"5jm87m9SCWs1","outputId":"cc54a04f-652c-4747-fa0a-565a6afae8b7"},"outputs":[{"name":"stdout","output_type":"stream","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Requirement already satisfied: datasets in /usr/local/lib/python3.7/dist-packages (2.4.0)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from datasets) (1.21.6)\n","Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from datasets) (4.12.0)\n","Requirement already satisfied: dill<0.3.6 in /usr/local/lib/python3.7/dist-packages (from datasets) (0.3.5.1)\n","Requirement already satisfied: xxhash in /usr/local/lib/python3.7/dist-packages (from datasets) (3.0.0)\n","Requirement already satisfied: multiprocess in /usr/local/lib/python3.7/dist-packages (from datasets) (0.70.13)\n","Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.7/dist-packages (from datasets) (2.23.0)\n","Requirement already satisfied: pyarrow>=6.0.0 in /usr/local/lib/python3.7/dist-packages (from datasets) (6.0.1)\n","Requirement already satisfied: aiohttp in /usr/local/lib/python3.7/dist-packages (from datasets) (3.8.1)\n","Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from datasets) (1.3.5)\n","Requirement already satisfied: huggingface-hub<1.0.0,>=0.1.0 in /usr/local/lib/python3.7/dist-packages (from datasets) (0.9.1)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from datasets) (21.3)\n","Requirement already satisfied: fsspec[http]>=2021.11.1 in /usr/local/lib/python3.7/dist-packages (from datasets) (2022.7.1)\n","Requirement already satisfied: responses<0.19 in /usr/local/lib/python3.7/dist-packages (from datasets) (0.18.0)\n","Requirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.7/dist-packages (from datasets) (4.64.0)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0.0,>=0.1.0->datasets) (4.1.1)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0.0,>=0.1.0->datasets) (3.8.0)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0.0,>=0.1.0->datasets) (6.0)\n","Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->datasets) (3.0.9)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->datasets) (2.10)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->datasets) (1.25.11)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->datasets) (2022.6.15)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->datasets) (3.0.4)\n","Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (4.0.2)\n","Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (1.8.1)\n","Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (1.2.0)\n","Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (1.3.1)\n","Requirement already satisfied: charset-normalizer<3.0,>=2.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (2.1.0)\n","Requirement already satisfied: asynctest==0.13.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (0.13.0)\n","Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (22.1.0)\n","Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (6.0.2)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->datasets) (3.8.1)\n","Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas->datasets) (2022.2.1)\n","Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas->datasets) (2.8.2)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7.3->pandas->datasets) (1.15.0)\n"]}],"source":["!pip install datasets"]},{"cell_type":"code","execution_count":4,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":3164,"status":"ok","timestamp":1661779936793,"user":{"displayName":"Philippe Lammerts","userId":"17702421406505717674"},"user_tz":-120},"id":"GrHRTFMkx6JT","outputId":"4297210c-8736-4849-a3a1-9b6ab29c5577"},"outputs":[{"name":"stdout","output_type":"stream","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Requirement already satisfied: tweet-preprocessor in /usr/local/lib/python3.7/dist-packages (0.6.0)\n"]}],"source":["!pip install tweet-preprocessor"]},{"cell_type":"code","execution_count":5,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":3181,"status":"ok","timestamp":1661779940217,"user":{"displayName":"Philippe Lammerts","userId":"17702421406505717674"},"user_tz":-120},"id":"ukBp_lH7o-OD","outputId":"d1ef3816-5490-4c8d-d402-ea2439de1f50"},"outputs":[{"name":"stdout","output_type":"stream","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Requirement already satisfied: ray[tune] in /usr/local/lib/python3.7/dist-packages (2.0.0)\n","Requirement already satisfied: msgpack<2.0.0,>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from ray[tune]) (1.0.4)\n","Requirement already satisfied: attrs in /usr/local/lib/python3.7/dist-packages (from ray[tune]) (22.1.0)\n","Requirement already satisfied: virtualenv in /usr/local/lib/python3.7/dist-packages (from ray[tune]) (20.16.3)\n","Requirement already satisfied: numpy>=1.16 in /usr/local/lib/python3.7/dist-packages (from ray[tune]) (1.21.6)\n","Requirement already satisfied: protobuf<4.0.0,>=3.15.3 in /usr/local/lib/python3.7/dist-packages (from ray[tune]) (3.17.3)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from ray[tune]) (3.8.0)\n","Requirement already satisfied: pyyaml in /usr/local/lib/python3.7/dist-packages (from ray[tune]) (6.0)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from ray[tune]) (4.1.1)\n","Requirement already satisfied: frozenlist in /usr/local/lib/python3.7/dist-packages (from ray[tune]) (1.3.1)\n","Requirement already satisfied: jsonschema in /usr/local/lib/python3.7/dist-packages (from ray[tune]) (4.3.3)\n","Requirement already satisfied: grpcio<=1.43.0,>=1.28.1 in /usr/local/lib/python3.7/dist-packages (from ray[tune]) (1.43.0)\n","Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from ray[tune]) (2.23.0)\n","Requirement already satisfied: click<=8.0.4,>=7.0 in /usr/local/lib/python3.7/dist-packages (from ray[tune]) (7.1.2)\n","Requirement already satisfied: aiosignal in /usr/local/lib/python3.7/dist-packages (from ray[tune]) (1.2.0)\n","Requirement already satisfied: tabulate in /usr/local/lib/python3.7/dist-packages (from ray[tune]) (0.8.10)\n","Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from ray[tune]) (1.3.5)\n","Requirement already satisfied: tensorboardX>=1.9 in /usr/local/lib/python3.7/dist-packages (from ray[tune]) (2.5.1)\n","Requirement already satisfied: six>=1.5.2 in /usr/local/lib/python3.7/dist-packages (from grpcio<=1.43.0,>=1.28.1->ray[tune]) (1.15.0)\n","Requirement already satisfied: pyrsistent!=0.17.0,!=0.17.1,!=0.17.2,>=0.14.0 in /usr/local/lib/python3.7/dist-packages (from jsonschema->ray[tune]) (0.18.1)\n","Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from jsonschema->ray[tune]) (4.12.0)\n","Requirement already satisfied: importlib-resources>=1.4.0 in /usr/local/lib/python3.7/dist-packages (from jsonschema->ray[tune]) (5.9.0)\n","Requirement already satisfied: zipp>=3.1.0 in /usr/local/lib/python3.7/dist-packages (from importlib-resources>=1.4.0->jsonschema->ray[tune]) (3.8.1)\n","Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas->ray[tune]) (2.8.2)\n","Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas->ray[tune]) (2022.2.1)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->ray[tune]) (1.25.11)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->ray[tune]) (2.10)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->ray[tune]) (2022.6.15)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->ray[tune]) (3.0.4)\n","Requirement already satisfied: platformdirs<3,>=2.4 in /usr/local/lib/python3.7/dist-packages (from virtualenv->ray[tune]) (2.5.2)\n","Requirement already satisfied: distlib<1,>=0.3.5 in /usr/local/lib/python3.7/dist-packages (from virtualenv->ray[tune]) (0.3.6)\n"]}],"source":["!pip install \"ray[tune]\""]},{"cell_type":"code","execution_count":6,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":3432,"status":"ok","timestamp":1661779943643,"user":{"displayName":"Philippe Lammerts","userId":"17702421406505717674"},"user_tz":-120},"id":"BAOeVax-qJ9v","outputId":"d16e4b42-7fb2-4072-d5bb-3f6c47964e16"},"outputs":[{"name":"stdout","output_type":"stream","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Requirement already satisfied: wordsegment in /usr/local/lib/python3.7/dist-packages (1.3.1)\n"]}],"source":["!pip install wordsegment"]},{"cell_type":"code","execution_count":7,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":5994,"status":"ok","timestamp":1661779949618,"user":{"displayName":"Philippe Lammerts","userId":"17702421406505717674"},"user_tz":-120},"id":"vSXQNkYz2dOO","outputId":"33451773-dfaf-475b-dbbf-dd4044e72473"},"outputs":[{"name":"stdout","output_type":"stream","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]}],"source":["from transformers import DistilBertForSequenceClassification, Trainer, TrainingArguments, DistilBertTokenizer\n","import numpy as np\n","from datasets import load_metric, load_dataset, Dataset\n","from sklearn.model_selection import train_test_split\n","import pickle\n","import torch\n","from google.colab import drive\n","import preprocessor as p\n","import html\n","from torch.utils.data import DataLoader\n","import torch.nn.functional as nn\n","from ray.tune.schedulers import PopulationBasedTraining\n","\n","# Mount drive for loading the datasets\n","drive.mount('/content/drive')\n","import sys\n","sys.path.insert(0, '/content/drive/MyDrive/Colab Notebooks/')\n","\n","from reader import Reader\n","\n","FILENAME = \"drive/MyDrive/Colab Notebooks/data/twitter_data.pkl\"\n","NUM_LABELS = 2"]},{"cell_type":"markdown","metadata":{"id":"3Zg836CxTD2g"},"source":["## Split and tokenize the datasets"]},{"cell_type":"code","execution_count":8,"metadata":{"executionInfo":{"elapsed":15,"status":"ok","timestamp":1661779949620,"user":{"displayName":"Philippe Lammerts","userId":"17702421406505717674"},"user_tz":-120},"id":"gx7YKv07TOl3"},"outputs":[],"source":["class HateDataset(torch.utils.data.Dataset):\n","    \"\"\"Dataset class used for combining the data encodings and labels.\"\"\"\n","    def __init__(self, encodings, labels):\n","        self.encodings = encodings\n","        self.labels = labels\n","\n","    def __getitem__(self, idx):\n","        item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n","        item['labels'] = torch.tensor(self.labels[idx])\n","        return item\n","\n","    def __len__(self):\n","        return len(self.labels)"]},{"cell_type":"code","execution_count":9,"metadata":{"executionInfo":{"elapsed":14253,"status":"ok","timestamp":1661779963861,"user":{"displayName":"Philippe Lammerts","userId":"17702421406505717674"},"user_tz":-120},"id":"vaNM4xTECiA4"},"outputs":[],"source":["X, y = Reader.load(FILENAME)\n","X = Reader.preprocess(X)\n","\n","mapping = {'racism': 1,'sexism': 1, 'none': 0}\n","y = [mapping[b] for b in y]\n","\n","# Split dataset into train, test, and validation\n","X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=10, stratify=y, test_size=0.10)\n","X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, random_state=10, test_size=.2)\n","tokenizer = DistilBertTokenizer.from_pretrained(\"distilbert-base-uncased\")\n","\n","# Tokenize all datasets\n","train_encodings = tokenizer(X_train, truncation=True, padding=True)\n","val_encodings = tokenizer(X_val, truncation=True, padding=True)\n","test_encodings = tokenizer(X_test, truncation=True, padding=True)\n","\n","# Combine the encodings with the labels to Torch datasets\n","train_dataset = HateDataset(train_encodings, y_train)\n","val_dataset = HateDataset(val_encodings, y_val)\n","test_dataset = HateDataset(test_encodings, y_test)"]},{"cell_type":"markdown","metadata":{"id":"c0X08H2VTte0"},"source":["## Load accuracy metric for the model's evaluation"]},{"cell_type":"code","execution_count":10,"metadata":{"executionInfo":{"elapsed":455,"status":"ok","timestamp":1661779964309,"user":{"displayName":"Philippe Lammerts","userId":"17702421406505717674"},"user_tz":-120},"id":"V0q4K3lnLNsj"},"outputs":[],"source":["metric = load_metric(\"accuracy\")\n","\n","def compute_metrics(eval_pred):\n","    logits, labels = eval_pred\n","    predictions = np.argmax(logits, axis=-1)\n","    return metric.compute(predictions=predictions, references=labels)"]},{"cell_type":"markdown","metadata":{"id":"r1NUgKx9TyEM"},"source":["## Setup DistilBERT model"]},{"cell_type":"code","execution_count":13,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1566,"status":"ok","timestamp":1661780123918,"user":{"displayName":"Philippe Lammerts","userId":"17702421406505717674"},"user_tz":-120},"id":"jkyB35W7CiOm","outputId":"41a7aa2d-79b1-4fd9-db28-f725338f3b80"},"outputs":[{"name":"stderr","output_type":"stream","text":["PyTorch: setting up devices\n","The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n","loading configuration file https://huggingface.co/distilbert-base-uncased/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/23454919702d26495337f3da04d1655c7ee010d5ec9d77bdb9e399e00302c0a1.91b885ab15d631bf9cee9dc9d25ece0afd932f2f5130eba28f2055b2220c0333\n","Model config DistilBertConfig {\n","  \"activation\": \"gelu\",\n","  \"architectures\": [\n","    \"DistilBertForMaskedLM\"\n","  ],\n","  \"attention_dropout\": 0.1,\n","  \"dim\": 768,\n","  \"dropout\": 0.1,\n","  \"hidden_dim\": 3072,\n","  \"initializer_range\": 0.02,\n","  \"max_position_embeddings\": 512,\n","  \"model_type\": \"distilbert\",\n","  \"n_heads\": 12,\n","  \"n_layers\": 6,\n","  \"pad_token_id\": 0,\n","  \"qa_dropout\": 0.1,\n","  \"seq_classif_dropout\": 0.2,\n","  \"sinusoidal_pos_embds\": false,\n","  \"tie_weights_\": true,\n","  \"transformers_version\": \"4.21.2\",\n","  \"vocab_size\": 30522\n","}\n","\n","loading weights file https://huggingface.co/distilbert-base-uncased/resolve/main/pytorch_model.bin from cache at /root/.cache/huggingface/transformers/9c169103d7e5a73936dd2b627e42851bec0831212b677c637033ee4bce9ab5ee.126183e36667471617ae2f0835fab707baa54b731f991507ebbb55ea85adb12a\n","Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertForSequenceClassification: ['vocab_layer_norm.bias', 'vocab_projector.weight', 'vocab_projector.bias', 'vocab_transform.bias', 'vocab_transform.weight', 'vocab_layer_norm.weight']\n","- This IS expected if you are initializing DistilBertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing DistilBertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.weight', 'pre_classifier.weight', 'classifier.bias', 'pre_classifier.bias']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]}],"source":["def model_init():\n","    return DistilBertForSequenceClassification.from_pretrained(\"distilbert-base-uncased\", num_labels=NUM_LABELS)\n","    \n","training_args = TrainingArguments(output_dir=\"train\", evaluation_strategy=\"epoch\")\n","\n","trainer = Trainer(\n","    model_init=model_init,\n","    args=training_args,\n","    train_dataset=train_dataset,\n","    eval_dataset=val_dataset ,\n","    compute_metrics=compute_metrics\n",")\n","\n","scheduler = PopulationBasedTraining(\n","        metric='objective',\n","        mode='max',\n","        perturbation_interval=600.0,\n","        hyperparam_mutations={\n","            \"per_device_train_batch_size\": [16, 32],\n","            \"learning_rate\": [2e-5, 3e-5, 5e-5],\n","            \"num_train_epochs\": [2, 3, 4]\n","        })"]},{"cell_type":"markdown","metadata":{"id":"2pNT0IfeT59n"},"source":["## Training"]},{"cell_type":"code","execution_count":14,"metadata":{"colab":{"base_uri":"https://localhost:8080/","output_embedded_package_id":"1dSllNm0Nq3ht4V8oGvTJV2_c6twTJCGm"},"executionInfo":{"elapsed":2882150,"status":"ok","timestamp":1661783007888,"user":{"displayName":"Philippe Lammerts","userId":"17702421406505717674"},"user_tz":-120},"id":"nvIsddm6T45B","outputId":"436810cc-98c2-4d78-b48e-c82d811aae29"},"outputs":[{"data":{"text/plain":["Output hidden; open in https://colab.research.google.com to view."]},"metadata":{},"output_type":"display_data"}],"source":["best_trial = trainer.hyperparameter_search(\n","    direction=\"maximize\", \n","    backend=\"ray\", \n","    n_trials=10,\n","    scheduler=scheduler\n",")"]},{"cell_type":"code","execution_count":15,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":263,"status":"ok","timestamp":1661783030940,"user":{"displayName":"Philippe Lammerts","userId":"17702421406505717674"},"user_tz":-120},"id":"pcYR0I7f57yx","outputId":"7c815362-199c-419b-d58f-5270fa578521"},"outputs":[{"name":"stdout","output_type":"stream","text":["BestRun(run_id='73c1a_00005', objective=0.8619261304798067, hyperparameters={'learning_rate': 1.1207606211860595e-05, 'num_train_epochs': 4, 'seed': 1.8994345766152145, 'per_device_train_batch_size': 16})\n"]}],"source":["print(best_trial)"]},{"cell_type":"code","execution_count":21,"metadata":{"executionInfo":{"elapsed":6,"status":"ok","timestamp":1661785298989,"user":{"displayName":"Philippe Lammerts","userId":"17702421406505717674"},"user_tz":-120},"id":"9gISBTgQF4OW"},"outputs":[],"source":["learning_rate = best_trial.hyperparameters['learning_rate']\n","num_train_epochs = best_trial.hyperparameters['num_train_epochs']\n","per_device_train_batch_size = best_trial.hyperparameters['per_device_train_batch_size']\n","seed = best_trial.hyperparameters['seed']"]},{"cell_type":"code","execution_count":26,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"elapsed":347287,"status":"ok","timestamp":1661785774612,"user":{"displayName":"Philippe Lammerts","userId":"17702421406505717674"},"user_tz":-120},"id":"a9No56bsCUtN","outputId":"4091a37f-46e1-4be1-a222-0ea98076a7c8"},"outputs":[{"name":"stderr","output_type":"stream","text":["loading configuration file https://huggingface.co/distilbert-base-uncased/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/23454919702d26495337f3da04d1655c7ee010d5ec9d77bdb9e399e00302c0a1.91b885ab15d631bf9cee9dc9d25ece0afd932f2f5130eba28f2055b2220c0333\n","Model config DistilBertConfig {\n","  \"activation\": \"gelu\",\n","  \"architectures\": [\n","    \"DistilBertForMaskedLM\"\n","  ],\n","  \"attention_dropout\": 0.1,\n","  \"dim\": 768,\n","  \"dropout\": 0.1,\n","  \"hidden_dim\": 3072,\n","  \"initializer_range\": 0.02,\n","  \"max_position_embeddings\": 512,\n","  \"model_type\": \"distilbert\",\n","  \"n_heads\": 12,\n","  \"n_layers\": 6,\n","  \"pad_token_id\": 0,\n","  \"qa_dropout\": 0.1,\n","  \"seq_classif_dropout\": 0.2,\n","  \"sinusoidal_pos_embds\": false,\n","  \"tie_weights_\": true,\n","  \"transformers_version\": \"4.21.2\",\n","  \"vocab_size\": 30522\n","}\n","\n","loading weights file https://huggingface.co/distilbert-base-uncased/resolve/main/pytorch_model.bin from cache at /root/.cache/huggingface/transformers/9c169103d7e5a73936dd2b627e42851bec0831212b677c637033ee4bce9ab5ee.126183e36667471617ae2f0835fab707baa54b731f991507ebbb55ea85adb12a\n","Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertForSequenceClassification: ['vocab_layer_norm.bias', 'vocab_projector.weight', 'vocab_projector.bias', 'vocab_transform.bias', 'vocab_transform.weight', 'vocab_layer_norm.weight']\n","- This IS expected if you are initializing DistilBertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing DistilBertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.weight', 'pre_classifier.weight', 'classifier.bias', 'pre_classifier.bias']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","/usr/local/lib/python3.7/dist-packages/transformers/optimization.py:310: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n","  FutureWarning,\n","***** Running training *****\n","  Num examples = 11584\n","  Num Epochs = 4\n","  Instantaneous batch size per device = 16\n","  Total train batch size (w. parallel, distributed & accumulation) = 16\n","  Gradient Accumulation steps = 1\n","  Total optimization steps = 5792\n"]},{"data":{"text/html":["\n","    <div>\n","      \n","      <progress value='5792' max='5792' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [5792/5792 05:46, Epoch 4/4]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Epoch</th>\n","      <th>Training Loss</th>\n","      <th>Validation Loss</th>\n","      <th>Accuracy</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>1</td>\n","      <td>0.386700</td>\n","      <td>0.376223</td>\n","      <td>0.846393</td>\n","    </tr>\n","    <tr>\n","      <td>2</td>\n","      <td>0.332700</td>\n","      <td>0.371816</td>\n","      <td>0.853642</td>\n","    </tr>\n","    <tr>\n","      <td>3</td>\n","      <td>0.254200</td>\n","      <td>0.458454</td>\n","      <td>0.856403</td>\n","    </tr>\n","    <tr>\n","      <td>4</td>\n","      <td>0.206200</td>\n","      <td>0.524698</td>\n","      <td>0.859510</td>\n","    </tr>\n","  </tbody>\n","</table><p>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["Saving model checkpoint to train/checkpoint-500\n","Configuration saved in train/checkpoint-500/config.json\n","Model weights saved in train/checkpoint-500/pytorch_model.bin\n","Saving model checkpoint to train/checkpoint-1000\n","Configuration saved in train/checkpoint-1000/config.json\n","Model weights saved in train/checkpoint-1000/pytorch_model.bin\n","***** Running Evaluation *****\n","  Num examples = 2897\n","  Batch size = 8\n","Saving model checkpoint to train/checkpoint-1500\n","Configuration saved in train/checkpoint-1500/config.json\n","Model weights saved in train/checkpoint-1500/pytorch_model.bin\n","Saving model checkpoint to train/checkpoint-2000\n","Configuration saved in train/checkpoint-2000/config.json\n","Model weights saved in train/checkpoint-2000/pytorch_model.bin\n","Saving model checkpoint to train/checkpoint-2500\n","Configuration saved in train/checkpoint-2500/config.json\n","Model weights saved in train/checkpoint-2500/pytorch_model.bin\n","***** Running Evaluation *****\n","  Num examples = 2897\n","  Batch size = 8\n","Saving model checkpoint to train/checkpoint-3000\n","Configuration saved in train/checkpoint-3000/config.json\n","Model weights saved in train/checkpoint-3000/pytorch_model.bin\n","Saving model checkpoint to train/checkpoint-3500\n","Configuration saved in train/checkpoint-3500/config.json\n","Model weights saved in train/checkpoint-3500/pytorch_model.bin\n","Saving model checkpoint to train/checkpoint-4000\n","Configuration saved in train/checkpoint-4000/config.json\n","Model weights saved in train/checkpoint-4000/pytorch_model.bin\n","***** Running Evaluation *****\n","  Num examples = 2897\n","  Batch size = 8\n","Saving model checkpoint to train/checkpoint-4500\n","Configuration saved in train/checkpoint-4500/config.json\n","Model weights saved in train/checkpoint-4500/pytorch_model.bin\n","Saving model checkpoint to train/checkpoint-5000\n","Configuration saved in train/checkpoint-5000/config.json\n","Model weights saved in train/checkpoint-5000/pytorch_model.bin\n","Saving model checkpoint to train/checkpoint-5500\n","Configuration saved in train/checkpoint-5500/config.json\n","Model weights saved in train/checkpoint-5500/pytorch_model.bin\n","***** Running Evaluation *****\n","  Num examples = 2897\n","  Batch size = 8\n","\n","\n","Training completed. Do not forget to share your model on huggingface.co/models =)\n","\n","\n"]},{"data":{"text/plain":["TrainOutput(global_step=5792, training_loss=0.2972884586502834, metrics={'train_runtime': 346.3271, 'train_samples_per_second': 133.793, 'train_steps_per_second': 16.724, 'total_flos': 935087367112704.0, 'train_loss': 0.2972884586502834, 'epoch': 4.0})"]},"execution_count":26,"metadata":{},"output_type":"execute_result"}],"source":["setattr(trainer.args, 'learning_rate', learning_rate)\n","setattr(trainer.args, 'num_train_epochs', num_train_epochs)\n","setattr(trainer.args, 'per_device_train_batch_size', per_device_train_batch_size)\n","setattr(trainer.args, 'seed', 42)\n","\n","trainer.train()"]},{"cell_type":"code","execution_count":30,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":941,"status":"ok","timestamp":1661786228263,"user":{"displayName":"Philippe Lammerts","userId":"17702421406505717674"},"user_tz":-120},"id":"KiWorLSMLTFP","outputId":"edcf8220-f679-4ab4-8876-cd47bfdf60ac"},"outputs":[{"name":"stderr","output_type":"stream","text":["Saving model checkpoint to drive/MyDrive/Colab Notebooks/output/distilbert-waseem-hovy.pth\n","Configuration saved in drive/MyDrive/Colab Notebooks/output/distilbert-waseem-hovy.pth/config.json\n","Model weights saved in drive/MyDrive/Colab Notebooks/output/distilbert-waseem-hovy.pth/pytorch_model.bin\n"]}],"source":["path = F\"drive/MyDrive/Colab Notebooks/output/distilbert-waseem-hovy.pth\" \n","trainer.save_model(path)"]},{"cell_type":"code","execution_count":31,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1340,"status":"ok","timestamp":1661786511015,"user":{"displayName":"Philippe Lammerts","userId":"17702421406505717674"},"user_tz":-120},"id":"2eghHl7fMNs1","outputId":"1ecefd81-ac51-4e64-f347-fb8f8e4fe052"},"outputs":[{"name":"stderr","output_type":"stream","text":["loading configuration file drive/MyDrive/Colab Notebooks/output/distilbert-waseem-hovy.pth/config.json\n","Model config DistilBertConfig {\n","  \"_name_or_path\": \"distilbert-base-uncased\",\n","  \"activation\": \"gelu\",\n","  \"architectures\": [\n","    \"DistilBertForSequenceClassification\"\n","  ],\n","  \"attention_dropout\": 0.1,\n","  \"dim\": 768,\n","  \"dropout\": 0.1,\n","  \"hidden_dim\": 3072,\n","  \"initializer_range\": 0.02,\n","  \"max_position_embeddings\": 512,\n","  \"model_type\": \"distilbert\",\n","  \"n_heads\": 12,\n","  \"n_layers\": 6,\n","  \"pad_token_id\": 0,\n","  \"problem_type\": \"single_label_classification\",\n","  \"qa_dropout\": 0.1,\n","  \"seq_classif_dropout\": 0.2,\n","  \"sinusoidal_pos_embds\": false,\n","  \"tie_weights_\": true,\n","  \"torch_dtype\": \"float32\",\n","  \"transformers_version\": \"4.21.2\",\n","  \"vocab_size\": 30522\n","}\n","\n","loading weights file drive/MyDrive/Colab Notebooks/output/distilbert-waseem-hovy.pth/pytorch_model.bin\n","All model checkpoint weights were used when initializing DistilBertForSequenceClassification.\n","\n","All the weights of DistilBertForSequenceClassification were initialized from the model checkpoint at drive/MyDrive/Colab Notebooks/output/distilbert-waseem-hovy.pth.\n","If your task is similar to the task the model of the checkpoint was trained on, you can already use DistilBertForSequenceClassification for predictions without further training.\n"]}],"source":["model = DistilBertForSequenceClassification.from_pretrained(path)"]},{"cell_type":"markdown","metadata":{"id":"NUIO_JgFVfZ3"},"source":["## Model calibration\n","We use temperature scaling to calibrate the model on the validation set by finding the optimal T value."]},{"cell_type":"code","execution_count":32,"metadata":{"executionInfo":{"elapsed":1150,"status":"ok","timestamp":1661786517736,"user":{"displayName":"Philippe Lammerts","userId":"17702421406505717674"},"user_tz":-120},"id":"ViXRjzkVWjv6"},"outputs":[],"source":["import sys\n","sys.path.append(\"drive/MyDrive/Colab Notebooks\")\n","from temperature_scaling import ModelWithTemperature\n"]},{"cell_type":"code","execution_count":33,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":12803,"status":"ok","timestamp":1661786533503,"user":{"displayName":"Philippe Lammerts","userId":"17702421406505717674"},"user_tz":-120},"id":"dXGs9Kb7g2at","outputId":"df48547c-5a77-45c6-bae6-59522f936b6d"},"outputs":[{"name":"stdout","output_type":"stream","text":["Before temperature - NLL: 0.406, ECE: 0.036\n","Optimal temperature: 1.338\n","After temperature - NLL: 0.403, ECE: 0.042\n"]},{"data":{"text/plain":["ModelWithTemperature(\n","  (model): DistilBertForSequenceClassification(\n","    (distilbert): DistilBertModel(\n","      (embeddings): Embeddings(\n","        (word_embeddings): Embedding(30522, 768, padding_idx=0)\n","        (position_embeddings): Embedding(512, 768)\n","        (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","        (dropout): Dropout(p=0.1, inplace=False)\n","      )\n","      (transformer): Transformer(\n","        (layer): ModuleList(\n","          (0): TransformerBlock(\n","            (attention): MultiHeadSelfAttention(\n","              (dropout): Dropout(p=0.1, inplace=False)\n","              (q_lin): Linear(in_features=768, out_features=768, bias=True)\n","              (k_lin): Linear(in_features=768, out_features=768, bias=True)\n","              (v_lin): Linear(in_features=768, out_features=768, bias=True)\n","              (out_lin): Linear(in_features=768, out_features=768, bias=True)\n","            )\n","            (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (ffn): FFN(\n","              (dropout): Dropout(p=0.1, inplace=False)\n","              (lin1): Linear(in_features=768, out_features=3072, bias=True)\n","              (lin2): Linear(in_features=3072, out_features=768, bias=True)\n","              (activation): GELUActivation()\n","            )\n","            (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","          )\n","          (1): TransformerBlock(\n","            (attention): MultiHeadSelfAttention(\n","              (dropout): Dropout(p=0.1, inplace=False)\n","              (q_lin): Linear(in_features=768, out_features=768, bias=True)\n","              (k_lin): Linear(in_features=768, out_features=768, bias=True)\n","              (v_lin): Linear(in_features=768, out_features=768, bias=True)\n","              (out_lin): Linear(in_features=768, out_features=768, bias=True)\n","            )\n","            (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (ffn): FFN(\n","              (dropout): Dropout(p=0.1, inplace=False)\n","              (lin1): Linear(in_features=768, out_features=3072, bias=True)\n","              (lin2): Linear(in_features=3072, out_features=768, bias=True)\n","              (activation): GELUActivation()\n","            )\n","            (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","          )\n","          (2): TransformerBlock(\n","            (attention): MultiHeadSelfAttention(\n","              (dropout): Dropout(p=0.1, inplace=False)\n","              (q_lin): Linear(in_features=768, out_features=768, bias=True)\n","              (k_lin): Linear(in_features=768, out_features=768, bias=True)\n","              (v_lin): Linear(in_features=768, out_features=768, bias=True)\n","              (out_lin): Linear(in_features=768, out_features=768, bias=True)\n","            )\n","            (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (ffn): FFN(\n","              (dropout): Dropout(p=0.1, inplace=False)\n","              (lin1): Linear(in_features=768, out_features=3072, bias=True)\n","              (lin2): Linear(in_features=3072, out_features=768, bias=True)\n","              (activation): GELUActivation()\n","            )\n","            (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","          )\n","          (3): TransformerBlock(\n","            (attention): MultiHeadSelfAttention(\n","              (dropout): Dropout(p=0.1, inplace=False)\n","              (q_lin): Linear(in_features=768, out_features=768, bias=True)\n","              (k_lin): Linear(in_features=768, out_features=768, bias=True)\n","              (v_lin): Linear(in_features=768, out_features=768, bias=True)\n","              (out_lin): Linear(in_features=768, out_features=768, bias=True)\n","            )\n","            (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (ffn): FFN(\n","              (dropout): Dropout(p=0.1, inplace=False)\n","              (lin1): Linear(in_features=768, out_features=3072, bias=True)\n","              (lin2): Linear(in_features=3072, out_features=768, bias=True)\n","              (activation): GELUActivation()\n","            )\n","            (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","          )\n","          (4): TransformerBlock(\n","            (attention): MultiHeadSelfAttention(\n","              (dropout): Dropout(p=0.1, inplace=False)\n","              (q_lin): Linear(in_features=768, out_features=768, bias=True)\n","              (k_lin): Linear(in_features=768, out_features=768, bias=True)\n","              (v_lin): Linear(in_features=768, out_features=768, bias=True)\n","              (out_lin): Linear(in_features=768, out_features=768, bias=True)\n","            )\n","            (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (ffn): FFN(\n","              (dropout): Dropout(p=0.1, inplace=False)\n","              (lin1): Linear(in_features=768, out_features=3072, bias=True)\n","              (lin2): Linear(in_features=3072, out_features=768, bias=True)\n","              (activation): GELUActivation()\n","            )\n","            (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","          )\n","          (5): TransformerBlock(\n","            (attention): MultiHeadSelfAttention(\n","              (dropout): Dropout(p=0.1, inplace=False)\n","              (q_lin): Linear(in_features=768, out_features=768, bias=True)\n","              (k_lin): Linear(in_features=768, out_features=768, bias=True)\n","              (v_lin): Linear(in_features=768, out_features=768, bias=True)\n","              (out_lin): Linear(in_features=768, out_features=768, bias=True)\n","            )\n","            (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (ffn): FFN(\n","              (dropout): Dropout(p=0.1, inplace=False)\n","              (lin1): Linear(in_features=768, out_features=3072, bias=True)\n","              (lin2): Linear(in_features=3072, out_features=768, bias=True)\n","              (activation): GELUActivation()\n","            )\n","            (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","          )\n","        )\n","      )\n","    )\n","    (pre_classifier): Linear(in_features=768, out_features=768, bias=True)\n","    (classifier): Linear(in_features=768, out_features=2, bias=True)\n","    (dropout): Dropout(p=0.2, inplace=False)\n","  )\n",")"]},"execution_count":33,"metadata":{},"output_type":"execute_result"}],"source":["calibrated_model = ModelWithTemperature(model)\n","val_loader = DataLoader(val_dataset)\n","\n","# Find optimal T value to calibrate the model\n","calibrated_model.set_temperature(val_loader)\n"]},{"cell_type":"markdown","metadata":{"id":"KJ7eDVh_f3Zc"},"source":["## Export model"]},{"cell_type":"code","execution_count":34,"metadata":{"executionInfo":{"elapsed":1449,"status":"ok","timestamp":1661786563168,"user":{"displayName":"Philippe Lammerts","userId":"17702421406505717674"},"user_tz":-120},"id":"yQtB3k3hf5SY"},"outputs":[],"source":["path = F\"drive/MyDrive/Colab Notebooks/output/distilbert-waseem-hovy-calibrated.pth\" \n","torch.save(calibrated_model, path)"]}],"metadata":{"accelerator":"GPU","colab":{"collapsed_sections":[],"machine_shape":"hm","name":"Train DistilBERT.ipynb","provenance":[]},"gpuClass":"standard","kernelspec":{"display_name":"Python 3.8.5 ('smart-rejector')","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.5"},"vscode":{"interpreter":{"hash":"1d6d5fb1668883c33dcb7e6d97ab558619c066a76f945629b031854efe98e76a"}}},"nbformat":4,"nbformat_minor":0}
