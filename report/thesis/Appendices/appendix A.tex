\chapter{Survey}
\label{sec:appendix}
This appendix contains all the presentation material of the survey: the consent, explanation texts, and some examples of scenarios.
\section{Consent}
\begin{flushleft}
    You are being invited to participate in a research study titled "Costs of predictions in hate speech detection". This study is being done by Philippe Lammerts from the TU Delft.
\end{flushleft}
\begin{flushleft}
    The purpose of this research study is to find out what social media users think of different scenarios of hate speech detection on social media. It will take you approximately 22 minutes to complete. These scenarios consist of two things. First, we show a specific social media post that can be either hateful or not hateful. You need to indicate if you feel that the post is hateful or not. Second,  we explain how the social media platform dealt with this post. You need to indicate whether you agree/disagree/are neutral about the platform's decision. The results of the survey will be used in my thesis.
\end{flushleft}
\begin{flushleft}
    As with any online activity, the risk of a breach is always possible. To the best of our ability, your answers in this study will remain confidential. We will minimize any risks by making this survey completely anonymous. Therefore, please do not provide any personal information anywhere. The anonymous results might be shared publicly in the future.
\end{flushleft}
\begin{flushleft}
    Your participation in this study is entirely voluntary, and you can withdraw at any time.
\end{flushleft}
\begin{flushleft}
    Warning: some of the scenarios used in this experiment contain harmful and offensive content that may make some people feel uncomfortable.
\end{flushleft}
\begin{flushleft}
    Feel free to contact me with any questions or feedback you might have:
    p.m.lammerts@student.tudelft.nl
\end{flushleft}

\section{Introduction}
\subsection{Short introduction ME}
\begin{itemize}
    \item You will be presented with a series of different scenarios.
    \item For each scenario, you need to answer two questions.
    \item We will explain the exact instructions later.
    \item But first, we will let you familiarize yourself with a scale called Magnitude Estimation.
\end{itemize}

\subsection{Short introduction 100}
\begin{itemize}
    \item You will be presented with a series of different scenarios.
    \item For each scenario, you need to answer two questions.
    \item We will explain the exact instructions in the next page.
\end{itemize}


\subsection{Introduction}
You will be presented with a series of different scenarios.
\begin{itemize}
    \item Each scenario describes a situation of a social media user who wants to post a specific message on a fictional social media platform we now call SocialNet.
    \item These posts can be neutral or contain hateful content.
    \item SocialNet uses automated detection systems for detecting hate speech.
    \item When doing the study, you should be aware that it is expected for SocialNet to correctly classify hate speech. Wrong classifications are undesirable as they may cause harm to people.
\end{itemize}

\begin{flushleft}
    Each scenario describes one of the following situations for a specific social media post:
\end{flushleft}

\begin{enumerate}
    \item \textbf{You are a user of the SocialNet platform and have \textbf{not} seen this post on your main feed because SocialNet's automated detection system is confident that it is hateful.}
          \begin{itemize}
              \item You can still find this post when you scroll down your feed since SocialNet ranks hateful posts lower.
              \item If the post is not hateful after all, then the detection system was incorrect. This neutral post is now ranked lower on people's feeds with the consequence that the post cannot easily reach the author's followers.
              \item If the post is indeed hateful, then the detection system was correct.
          \end{itemize}
    \item \textbf{You are a user of the SocialNet platform and just saw this post on your main feed because SocialNet's automated detection system is confident that it is \textbf{not hateful}.}
          \begin{itemize}
              \item This post remains visible on other people's main feeds as well.
              \item If the post is hateful after all, then the detection system was incorrect. This hateful post is now visible on people's main feeds with the consequence that they can get harmed.
              \item If the post is indeed not hateful, then the detection system was correct.
          \end{itemize}
    \item \textbf{You are a user of the SocialNet platform and just saw this post on your main feed because SocialNet's automated detection system was not confident enough in whether it was hateful or not.}
          \begin{itemize}
              \item An internal human moderator at SocialNet needs to look at it within at most 24 hours.
              \item Meanwhile, the post remains visible on people's main feeds.
          \end{itemize}
\end{enumerate}

\section{Scales}
\subsection{100-level scale explanation}
For each scenario, you need to answer two questions:
\begin{enumerate}
    \item First, you need to indicate whether you feel that this post is hateful or not hateful.
    \item Second, your task is to tell how you feel about SocialNet's decision.
          \begin{itemize}
              \item If you feel neutral about SocialNet's decision, this value will be equal to 0.
              \item If you (dis)agree with the decision, you need to indicate how much you (dis)agree by assigning any number between 1 and 100.
              \item A large number means you (dis)agree with it a lot, while a small number means you (dis)agree with it a little.
              \item Try to make each number match the intensity as you perceive it.
          \end{itemize}
\end{enumerate}

\begin{flushleft}
    Don't worry, we will provide the same explanations in the questions as well.
\end{flushleft}

\subsection{ME scale explanation}
The following text is based on the survey setup from \citet{moskowitz1977magnitude}.\\

\begin{flushleft}
    For each scenario, you need to answer two questions:
\end{flushleft}

\begin{enumerate}
    \item First, you need to indicate whether you feel that this post is hateful or not hateful.
    \item Second, your task is to tell how you feel about SocialNet's decision.
          \begin{itemize}
              \item If you feel neutral about SocialNet's decision, this value will be equal to 0.
              \item If you (dis)agree with the decision from SocialNet, you need to assign any number that is greater or equal to 0 that reflects how much you (dis)agree with the decision.
              \item Assign any number that seems appropriate to you.
              \item A large number means you (dis)agree a lot, while a small number means you (dis)agree a little.
              \item If you (dis)agree twice as much with the current decision as with the previous one, you need to assign a number that is twice as large as the previous number.
              \item Or, if you (dis)agree half as much with the current decision as with the previous one, you need to assign a number that is half as large as the previous number.
              \item You can use any number or decimal you want, but make each assignment proportional to your subjective impression.
              \item Please try to not only use appropriate numbers but also avoid restricting your choice of numbers from 1 to 10.
              \item Try to remember which values you used before and to compare succeeding scenarios with each other.
          \end{itemize}
\end{enumerate}

\begin{flushleft}
    Don't worry, we will provide the same explanations in the questions as well.
\end{flushleft}

\section{Training phase ME}
``As a warm-up task, to familiarize you with magnitude estimation, you will be shown a sequence of five lines, one at a time.
\begin{itemize}
    \item For each line, enter a number into the text box below the displayed line. This number should reflect your perception of the length of the line. You may use any numbers that seem appropriate to you—whole numbers or decimals. However, you may not use negative numbers or zero.
    \item For each subsequent line, enter a number that reflects your perception of its length, relative to the previous line. For example, if you feel that the current line is twice as long as the previous, then you should assign a number that is twice as large as the number you used previously.
\end{itemize}

\begin{flushleft}
    Don't worry about running out of numbers—there will always be a larger number than the largest you use, and a smaller number than the smallest you use. Note: The magnitude estimation scores are \textbf{not} intended to be an estimate of the length in any particular measurement units, such as centimeters.'' \citep{maddalena2017crowdsourcing}
\end{flushleft}

\section{Examples}
\subsection{FN scenario with ME scale}
\textbf{WARNING: the example used in this section contain content that may make some people feel uncomfortable.}

\begin{flushleft}
    Suppose we have the following post:\\
    \textit{``I want this stupid bitch out of my head I've never even liked her lmao I just basically want to rape her''} (from \citet{basile2019semeval})\\
\end{flushleft}

\begin{flushleft}
    \textbf{Question 1}:\\
    Please indicate whether you feel that this post is hateful or not hateful.\\

    **Select input with options: 'hateful' or 'not hateful'**\\
\end{flushleft}

\begin{flushleft}
    \textbf{Question 2}:\\
    You are a user of the SocialNet platform and just saw this post on your main feed because SocialNet's automated detection system is confident that it is not hateful.
\end{flushleft}

\begin{itemize}
    \item This post remains visible on other people's main feeds as well.
    \item If the post is hateful after all, then the detection system was incorrect. This hateful post is now visible on people's main feeds with the consequence that they can get harmed.
    \item If the post is indeed not hateful, then the detection system was correct.
    \item You should be aware that it is expected for SocialNet to correctly classify hate speech. Wrong classifications are undesirable as they may cause harm to people.
\end{itemize}

\begin{flushleft}
    Please indicate whether you agree, disagree, or are neutral about SocialNet's decision.\\

    **Select input with options: 'agree', 'neutral', or 'disagree'.**\\
\end{flushleft}

\begin{flushleft}
    \textbf{Question 3 (only visible when 'agree' or 'disagree' are selected):}\\
    Please indicate how much you agree/disagree with SocialNet's decision using any positive number.\\

    **Show ME input field that allows all positive values greater than 0.**
\end{flushleft}

\subsection{FP scenario with 100-level scale}
\begin{flushleft}
    Suppose we have the following post:

    \textit{``Ontario concerns were not listened at immigration meeting in Ottawa For illegal crossing''} (from \citet{basile2019semeval})\\
\end{flushleft}

\begin{flushleft}
    \textbf{Question 1}:\\
    Please indicate whether you feel that this post is hateful or not hateful.\\

    **Select input with options: 'hateful' or 'not hateful'**\\
\end{flushleft}

\begin{flushleft}
    \textbf{Question 2}:\\
    You are a user of the SocialNet platform and have not seen this post on your main feed because SocialNet's automated detection system is confident that it is hateful.
\end{flushleft}

\begin{itemize}
    \item You can still find this post when you scroll down your feed since SocialNet ranks hateful posts lower.
    \item If the post is not hateful after all, then the detection system was incorrect. This neutral post is now ranked lower on people's feeds with the consequence that the post cannot easily reach the author's followers.
    \item If the post is indeed hateful, then the detection system was correct.
    \item You should be aware that it is expected for SocialNet to correctly classify hate speech. Wrong classifications are undesirable as they may cause harm to people.
\end{itemize}

\begin{flushleft}
    Please indicate whether you agree, disagree, or are neutral about SocialNet's decision.

    **Select input with options: 'agree', 'neutral', or 'disagree'.**\\
\end{flushleft}

\begin{flushleft}
    \textbf{Question 3 (only visible when 'agree' or 'disagree' are selected):}\\
    Please indicate how much you agree/disagree with SocialNet's decision using any positive number from 1 to 100. If you feel neutral about SocialNet's decision, select neutral in the field above.


    **Show a numerical slider with values between 1 and 100.**\\
\end{flushleft}


\subsection{Rejection scenario with 100-level scale}
\begin{flushleft}
    Suppose we have the following post:

    \textit{``Ever been so hungover that your stomach feels like it's eating itself''} (from \citet{basile2019semeval})\\
\end{flushleft}

\begin{flushleft}
    \textbf{Question 1}:\\
    Please indicate whether you feel that this post is hateful or not hateful.\\

    **Select input with options: 'hateful' or 'not hateful'**\\
\end{flushleft}

\begin{flushleft}
    \textbf{Question 2}:\\
    You are a user of the SocialNet platform and just saw this post on your main feed because SocialNet's automated detection system was not confident enough in whether it was hateful or not.
\end{flushleft}
\begin{itemize}
    \item An internal human moderator at SocialNet needs to look at it within at most 24 hours.
    \item Meanwhile, the post remains visible on people's main feeds.
\end{itemize}

\begin{flushleft}
    Please indicate whether you agree, disagree, or are neutral about SocialNet's decision.\\

    **Select input with options: 'agree', 'neutral', or 'disagree'.**\\
\end{flushleft}

\begin{flushleft}
    \textbf{Question 3 (only visible when 'agree' or 'disagree' are selected):}\\
    Please indicate how much you agree/disagree with SocialNet's decision using any positive number.\\

    **Show a numerical slider with values between 1 and 100.**\\
\end{flushleft}
