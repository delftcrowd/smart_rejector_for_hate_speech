\chapter{Value-sensitive rejection}
As concluded in the \nameref{sec:related-work}, there is a need for \textit{value-sensitive} metrics for measuring the performance of ML models, especially for social-technical applications such as hate speech detection.
%
We also concluded that manual human moderation is the most effective and that most automatic hate speech detection methods do not perform well on unseen data.
%
Therefore, in this project, we focus on rejecting ML predictions in a value-sensitive manner.
%
We do this by taking the values of TP, TN, FP, FN, and rejected predictions into account.
%
% Correct predictions (TP and TN) result in positive value (gains), while incorrect (FP and FN) and rejected predictions result in negative value (costs).
%
Section \ref{sec:survey} will explain how we assess these values.
%
For the remaining part of this chapter, we assume that we know these values.
%

%
In this chapter, we explain how we create a dependent rejector by introducing a confidence metric that measures the total value of an ML model with a reject option.
%
In \ref{sec:value-metric}, we explain how we construct the confidence metric, and in \ref{sec:state-of-the-art}, we discuss how we apply the metric to some of the state-of-the-art hate speech classification models.

\section{Value metric}
\label{sec:value-metric}
The idea of a rejecting ML predictions using a treshold is that for some treshold value $\tau$ in the range $[0, 1]$, we accept all predictions with confidence values that are greater than or equal to $\tau$ and reject all predictions with confidence values below $\tau$.
%
We use a confidence metric to find the optimal rejection threshold.
%
Here, we introduce our confidence metric as the value function $V(\tau)$ that measures the total value of some ML model with rejection threshold $\tau$.
%
We can determine the optimal rejection threshold by finding the $\tau$ value for which $V(\tau)$ is maximum.
%
The value of $V(\tau)$ depends on the values of TP, TN, FP, FN, and rejected predictions and is calculated for a set of predictions with their corresponding confidence values and actual labels.
%
We denote the values of TP, TN, FP, FN, and rejected predictions as $V_{tp}$, $V_{tn}$, $V_{fp}$, $V_{fn}$, and $V_r$ respectively.
%
From the set of predictions we can derive the subsets of TP, TN, FP, and FN predictions.
%
Note that we consider that $V_{tp}$ and $V_{tn}$ can be expressed as gains and, therefore, non-negative values and that $V_{fp}$, $V_{fn}$, and $V_{r}$ can be expressed costs and, therefore, non-positive values.
%
There is one condition that needs to hold: the reduction of total value by means of a rejection should always be smaller in magnitude than the value reduction of an incorrect prediction.
%
Otherwise adopting the reject option serves no purpose.
%
This condition can be formulated as:
% 
\begin{align}
    \label{for:value-condition}
    \frac{V_{FP} + V_{FN}}{2} < V_R,
\end{align}
%
For each $\tau$ value in $[0, 1]$, we would like to know whether the model with the reject option is more effective (increased $V(\tau)$) or less effective (decreased $V(\tau_)$ value).
%
In general, the metric should take the following conditions into account:
% 
\begin{enumerate}
    \item Correct accepted predictions should increase the value of $V(\tau)$, while incorrect accepted predictions should decrease the value of $V(\tau)$.
    \item Correct rejected predictions should decrease the value of $V(\tau)$, while incorrect rejected predictions should increase the value of $V(\tau)$.
\end{enumerate}
% 
We can convert these conditions into the following equations:
\begin{subequations}
    \label{for:conditions}
    \begin{align}
        \frac{\partial V}{\partial R_{tp}(\tau)} + \frac{\partial V}{\partial R_{tn}(\tau)} > 0, &  &
        \frac{\partial V}{\partial R^r_{tp}(\tau)} + \frac{\partial V}{\partial R^r_{tn}(\tau)} < 0, \label{for:conditions-tp-tn} \\
        \frac{\partial V}{\partial R_{fp}(\tau)} + \frac{\partial V}{\partial R_{fn}(\tau)} < 0, &  &
        \frac{\partial V}{\partial R^r_{fp}(\tau)} + \frac{\partial V}{\partial R^r_{fn}(\tau)} > 0, \label{for:conditions-fp-fn}
    \end{align}
\end{subequations}
%
where $R_t(\tau)$ and $R_t^r(\tau)$ are the fractions of accepted and rejected predictions respectively based on the rejection threshold $\tau$ and where $t \in [tp, tn, fp, fn]$.
%
We create a linear $V(\tau)$ function and assume that the values $V_t$ are known constants.
%
Subsequently, we can formulate $V(\tau)$ as:
\begin{align}
    \label{for:V}
    V(\tau) = \sum_{t} (V_t - V_r)R_t(\tau) + \sum_{t} (V_r - V_t)R^r_{t}(\tau),
\end{align}
%
where $t \in [tp, tn, fp, fn]$.
%
Conditions \ref{for:conditions-tp-tn} are satisfied by default since we assume that $V_{tp}$ and $V_{tn}$ are non-negative and $V_r$ is non-positive.
%
Conditions \ref{for:conditions-fp-fn} are satisfied under the condition of \ref{for:value-condition} and since we assume that $V_{fp}$, $V_{fn}$, and $V_r$ are negative.
% 
We can define the $R_t$ and the $R_t^r$ values by computing the integrals over the probability density functions (PDF) of the confidence values of the predictions with type $t$.
%
We can define $R_t$ by taking the integral over the interval $[\tau, 1]$, and $R_t^r$ by taking the integral over the interval $[0, \tau]$:
%
\begin{align}
    \label{for:R}
    \begin{aligned}
        R_{t}(\tau) = \int_\tau^1 D_{t}(x)dx & \quad & R_{t}^r(\tau) = \int_0^\tau D_{t}(x)dx
    \end{aligned}
\end{align}
%
By inserting the integrals from \ref{for:R} into \ref{for:V}, we get our final value function:
%
\begin{align}
    \label{for:final-V}
    V(\tau) = \sum_{t} (V_t - V_r)\int_\tau^1 D_{t}(x)dx + \sum_{t} (V_r - V_t)\int_0^\tau D_{t}(x)dx,
\end{align}
%
where $t \in [tp, tn, fp, fn]$ and $\tau$ is the rejection threhsold.
%
We can now use \ref{for:final-V} to calculate the total value of some ML model for all $\tau \in [0, 1]$ values.
%
The theoretical optimal rejection threshold is equal to the $\tau$ value for which we achieve the maximum value of $V(\tau)$.


\section{State-of-the-art}
\label{sec:state-of-the-art}
\subsection{Models}
\todo[inline]{Explain that we are going to use one traditional ML model (Logistic Regression since in related work we found that this got the best performance), one DL model (CNN because of the same reason), and a transformer model (DistilBERT given the recent popularity of transformer models)}

\subsection{Calibration}
\todo[inline]{Explain what model calibration is and why it's necessary}

\subsection{Datasets}
\todo[inline]{Explain that we are going to use the SemEval and Waseem datasets and the concepts of seen and unseen data}

\subsection{Calculating the total value}
\todo[inline]{Explain how we are going to apply our metric to the trained state-of-the-art models to calculate the optimal rejection threshold given the values of TP, TN, FP, FN, and rejection (that we still need estimate)}
\todo[inline]{Explain that we use Kernel Density Estimation to calculate the PDF functions (or stick to prediction counts as in the paper).}
